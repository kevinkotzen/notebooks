{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"  # Set the GPU you wish to use here\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], enable=True)\n",
    "\n",
    "from tensorflow.python.keras import Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Conv1D, GlobalAveragePooling1D, AveragePooling1D, MaxPool1D, Flatten, Dense, \\\n",
    "    Reshape, Dropout, TimeDistributed, Add, LSTM, GRU, Bidirectional\n",
    "from tensorflow.python.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "from multiprocessing import Manager, Pool\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "os.chdir('/home/kkotzen/research/PPG_sleepstaging/')\n",
    "from src.models.model_utils import plot_hypnogram\n",
    "from src.parsing.MESAParser import MESAParser\n",
    "\n",
    "# Sleep Stage Settings\n",
    "WAKE, LIGHT, DEEP, REM = 0, 1, 2, 3\n",
    "sleep_string_encoding = {0: 'wake', 1: 'n1', 2: 'n2', 3: 'n3', 4: 'rem'}\n",
    "sleep_encoding = {'wake': WAKE, 'n1': LIGHT, 'n2': LIGHT, 'n3': DEEP, 'rem': REM}\n",
    "\n",
    "# Sequence Settings\n",
    "ihr_fs = 2 #128/60\n",
    "samples_per_epoch = 30 * ihr_fs\n",
    "total_epochs = 1200\n",
    "total_samples = int(samples_per_epoch*total_epochs)\n",
    "\n",
    "def comp_google_ihr(patient, dl):\n",
    "    beats = dl.load_annotation(patient, signal='EKG', annotator='epltd0', annotation='Peaks')\n",
    "    beats = beats/dl.ecg_fs\n",
    "    ibi = np.diff(beats)\n",
    "    beats = beats[:-1]+(beats[1:] - beats[:-1])/2\n",
    "\n",
    "    upper = np.percentile(ibi, 99)\n",
    "    lower = np.percentile(ibi, 1)\n",
    "    \n",
    "    ibi_filt_idx = np.where((ibi < upper) & (ibi > lower))\n",
    "    ibi = ibi[ibi_filt_idx]\n",
    "    beats = beats[ibi_filt_idx]\n",
    "    ihr = 1/ibi\n",
    "    ihr = (ihr - np.mean(ihr))/np.std(ihr)\n",
    "\n",
    "    x_2hz = np.arange(0, beats[-1], 1/2)\n",
    "    ihr_2hz = np.interp(x_2hz, beats, ihr)\n",
    "    return ihr_2hz\n",
    "\n",
    "\n",
    "def _time_series_subsequences(ts, window, hop=1):\n",
    "    assert len(ts.shape) == 1\n",
    "    shape = (int(int(ts.size - window) / hop + 1), window)\n",
    "    strides = ts.strides[0] * hop, ts.strides[0]\n",
    "    return np.lib.stride_tricks.as_strided(ts, shape=shape, strides=strides)\n",
    "\n",
    "\n",
    "def _batch_subsequenced_padded(X, win_len, hop):\n",
    "    assert X.shape[1]%hop == 0\n",
    "    padding = int(win_len/2 - hop/2)\n",
    "    X__ = np.zeros((X.shape[0], X.shape[1]+2*padding, X.shape[2]))\n",
    "    X__[:,padding:-padding,:] = X\n",
    "    X_ = np.zeros((X.shape[0], int(X.shape[1]/hop), win_len))\n",
    "    for i in range(X.shape[0]):\n",
    "        X_[i] = _time_series_subsequences(X__[i].flatten(), win_len, hop)\n",
    "    return X_\n",
    "\n",
    "\n",
    "def load_one_xy(patient):\n",
    "    \n",
    "    dl=MESAParser()\n",
    "    \n",
    "    patient = str(patient).zfill(4)\n",
    "              \n",
    "    ihr = comp_google_ihr(patient, dl)\n",
    "\n",
    "    x = np.arange(0, ihr.shape[0]/2, 1/2)\n",
    "    x_new = np.arange(0, ihr.shape[0]/(128/60), 60/128 )\n",
    "    f = interpolate.interp1d(x, ihr)\n",
    "    ihr = f(x_new)        \n",
    "\n",
    "    sleep = dl.load_sleep(patient)\n",
    "    sleep[sleep > 5] = 0\n",
    "    sleep = [sleep_string_encoding[s] for s in sleep]\n",
    "    sleep = np.array([sleep_encoding[s] for s in sleep])\n",
    "    sleep[sleep > 9] = 0\n",
    "\n",
    "    L = ihr.shape[0]\n",
    "    if L > total_samples:\n",
    "        L = total_samples\n",
    "    X = ihr[0:L]\n",
    "\n",
    "    L = sleep.shape[0]\n",
    "    if L > total_epochs:\n",
    "        L = total_epochs\n",
    "    Y = sleep[0:L]\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def load_XY(patients, parallel=False, n_cores=16):\n",
    "\n",
    "    batch_size = len(patients)\n",
    "    X = np.zeros((batch_size, total_samples))\n",
    "    Y = np.zeros((batch_size, total_epochs))\n",
    "    \n",
    "    if parallel:\n",
    "        pool = Pool(n_cores)\n",
    "        for i, r in tqdm(enumerate(pool.imap(load_one_xy, patients))):\n",
    "            x, y = r[0], r[1]\n",
    "            X[i,0:x.shape[0]], Y[i,0:y.shape[0]] = x, y \n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else: \n",
    "        for i, patient in tqdm(enumerate(patients)):\n",
    "            x, y = load_one_xy(patient)\n",
    "            X[i,0:x.shape[0]], Y[i,0:y.shape[0]] = x, y \n",
    "\n",
    "    return np.expand_dims(X,axis=2), Y\n",
    "\n",
    "def calc_class_sample_weights(ty, weight_adjustment=[]):\n",
    "    if len(ty.shape) == 1:\n",
    "        y = ty.reshape(ty.shape[0])\n",
    "    else:\n",
    "        y = ty.reshape(ty.shape[0] * ty.shape[1])\n",
    "    classes = np.unique(y)\n",
    "\n",
    "    if len(weight_adjustment) > 0 and len(weight_adjustment) != len(classes):\n",
    "        raise ValueError(\"The weight adjustment variable needs to have as many values as there are classes\")\n",
    "    elif len(weight_adjustment) == 0:\n",
    "        weight_adjustment = np.ones(len(classes))\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=classes, y=y) * weight_adjustment\n",
    "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    sample_weights = np.vectorize(class_weights.get)(ty)\n",
    "    return class_weights, sample_weights\n",
    "\n",
    "def duplicate(x):\n",
    "    return np.array([[x_]*2 for x_ in x]).flatten()\n",
    "\n",
    "def hold_line(t, x):\n",
    "    t = [i for i in t]\n",
    "    x = [i for i in x]\n",
    "    \n",
    "    if len(t) - len(x) == 0:\n",
    "            t.append(t[-1]+t[-1]-t[-2])\n",
    "    if len(t)-len(x) != 1:\n",
    "            raise ValueError()\n",
    "            \n",
    "    t_ = duplicate(t)[1:-1]\n",
    "    x_ = duplicate(x)\n",
    "    return t_, x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1576\n",
      "Train: 196\n",
      "Train: 196\n"
     ]
    }
   ],
   "source": [
    "dl = MESAParser()\n",
    "train_patients, test_patients= dl.get_train_test_patients_from_file()\n",
    "train_patients, validate_patients = train_test_split(train_patients, test_size = len(test_patients), random_state=6668)\n",
    "print(f'Train: {len(train_patients)}')\n",
    "print(f'Train: {len(validate_patients)}')\n",
    "print(f'Train: {len(test_patients)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1576, 72000, 1) (1576, 1200)\n",
      "(196, 72000, 1) (196, 1200)\n",
      "(196, 72000, 1) (196, 1200)\n"
     ]
    }
   ],
   "source": [
    "# train_X, train_Y = load_XY(train_patients, parallel=True, n_cores=8)\n",
    "# validate_X, validate_Y = load_XY(validate_patients, parallel=True, n_cores=8)\n",
    "# test_X, test_Y = load_XY(test_patients, parallel=True, n_cores=8)\n",
    "\n",
    "# np.savez(\"train.npz\", train_X=train_X, train_Y=train_Y)\n",
    "# np.savez(\"validate.npz\", validate_X=validate_X, validate_Y=validate_Y)\n",
    "# np.savez(\"test.npz\", test_X=test_X, test_Y=test_Y)\n",
    "\n",
    "train = np.load('train.npz')\n",
    "train_X, train_Y = train['train_X'], train['train_Y']\n",
    "validate = np.load('validate.npz')\n",
    "validate_X, validate_Y = validate['validate_X'], validate['validate_Y']\n",
    "test = np.load('test.npz')\n",
    "test_X, test_Y = test['test_X'], test['test_Y']\n",
    "\n",
    "train_Y[train_Y==9] = 0\n",
    "validate_Y[validate_Y==9] = 0\n",
    "test_Y[test_Y==9] = 0\n",
    "\n",
    "print(train_X.shape, train_Y.shape)\n",
    "print(validate_X.shape, validate_Y.shape)\n",
    "print(test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f4594874a74631bf367d22004c46c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa3ce90dca0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "# plt.plot(train_X[1])\n",
    "t, y = hold_line(np.arange(0,1201*30, 30),train_Y[400])\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "plt.plot(t, y)\n",
    "t, y = np.arange(0,train_X.shape[1]/2, 0.5), train_X[400]\n",
    "ax2=plt.subplot(2,1,2, sharex=ax1)\n",
    "plt.plot(t, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1576, 1200, 256) (1576, 1200)\n",
      "(196, 1200, 256) (196, 1200)\n",
      "(196, 1200, 256) (196, 1200)\n"
     ]
    }
   ],
   "source": [
    "win_len = 256\n",
    "samples_per_epoch = 30 * ihr_fs\n",
    "    \n",
    "train_X_, train_Y_ = _batch_subsequenced_padded(train_X, win_len, samples_per_epoch), train_Y\n",
    "validate_X_, validate_Y_ = _batch_subsequenced_padded(validate_X, win_len, samples_per_epoch), validate_Y\n",
    "test_X_, test_Y_ = _batch_subsequenced_padded(test_X, win_len, samples_per_epoch), test_Y\n",
    "\n",
    "print(train_X_.shape, train_Y_.shape)\n",
    "print(validate_X_.shape, validate_Y_.shape)\n",
    "print(test_X_.shape, test_Y_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cbe8542eddb4938b63f56d70d75fb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(4,1,1)\n",
    "plt.plot(train_X[1])\n",
    "plt.subplot(4,1,2)\n",
    "plt.plot(train_X_[1, 0, :])\n",
    "plt.subplot(4,1,3)\n",
    "plt.plot(train_X_[1, 1, :])\n",
    "plt.subplot(4,1,4)\n",
    "plt.plot(train_X_[1, 2, :])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(train_Y.flatten()).hist(density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Output Shape                            Param #        \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)                         [(None, 1200, 256, 1)]                  0              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed (TimeDistributed)           (None, 1200, 256, 8)                    16             \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistributed)         (None, 1200, 256, 16)                   400            \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistributed)         (None, 1200, 256, 16)                   784            \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistributed)         (None, 1200, 128, 16)                   0              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistributed)         (None, 1200, 128, 32)                   1568           \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistributed)         (None, 1200, 128, 32)                   3104           \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistributed)         (None, 1200, 64, 32)                    0              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistributed)         (None, 1200, 64, 64)                    6208           \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistributed)         (None, 1200, 64, 64)                    12352          \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistributed)         (None, 1200, 32, 64)                    0              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistributed)        (None, 1200, 2048)                      0              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistributed)        (None, 1200, 256)                       524544         \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)                (None, 1200, 256)                       394240         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistributed)        (None, 1200, 4)                         1028           \n",
      "====================================================================================================\n",
      "Total params: 944,244\n",
      "Trainable params: 944,244\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def dilated_residual_convolution(X_in, kernel, dilations, dropout, reg):\n",
    "    for dilation in dilations:\n",
    "        X = TimeDistributed(Conv1D(128, kernel_size=kernel,  activation='relu', dilation_rate=dilation, padding='same',  kernel_regularizer=reg))(X_in)\n",
    "    if dropout > 0:\n",
    "        X = TimeDistributed(Dropout(0.2))(X)\n",
    "    X = Add()([X, X_in])\n",
    "    return X\n",
    "\n",
    "def residual_convolution(X_in, kernel, filt, reg):\n",
    "    X = X_in\n",
    "    #Residual needs 1x1 CNN\n",
    "    X_residual = TimeDistributed(MaxPool1D(2, strides=2))(X)\n",
    "    X_residual = TimeDistributed(Conv1D(1, 1, activation='relu', padding='same'))(X_residual)\n",
    "    #Convolutions and max pooling\n",
    "    X = TimeDistributed(Conv1D(filt, kernel, activation='relu', padding='same',  kernel_regularizer=reg))(X)\n",
    "    X = TimeDistributed(Conv1D(filt, kernel, activation='relu', padding='same',  kernel_regularizer=reg))(X)\n",
    "    X = TimeDistributed(MaxPool1D(2, strides=2))(X)\n",
    "    #Bring in the residual\n",
    "    X = Add()([X, X_residual])\n",
    "    return X\n",
    "\n",
    "\n",
    "def convolution(X_in, kernel, filt, reg):\n",
    "    X = X_in\n",
    "    #Convolutions and max pooling\n",
    "    X = TimeDistributed(Conv1D(filt, kernel, activation='relu', padding='same',  kernel_regularizer=reg))(X)\n",
    "    X = TimeDistributed(Conv1D(filt, kernel, activation='relu', padding='same',  kernel_regularizer=reg))(X)\n",
    "    X = TimeDistributed(MaxPool1D(2, strides=2))(X)\n",
    "    #Bring in the residual\n",
    "    return X\n",
    "\n",
    "reg = 'l1'\n",
    "\n",
    "inputs = Input(shape=(validate_X_.shape[1], validate_X_.shape[2], 1))\n",
    "\n",
    "# Input Convolution\n",
    "X = TimeDistributed(Conv1D(8, 1, activation='relu', padding='same', kernel_regularizer=reg))(inputs)\n",
    "X = convolution(X, kernel=3, filt=16, reg=reg)\n",
    "X = convolution(X, kernel=3, filt=32, reg=reg)\n",
    "X = convolution(X, kernel=3, filt=64, reg=reg)\n",
    "X = TimeDistributed(Flatten())(X)\n",
    "X = TimeDistributed(Dense(units=256, activation='relu'))(X)\n",
    "# X = Reshape(target_shape=(1, X.shape[1], X.shape[2]))(X)\n",
    "# X = dilated_residual_convolution(X, kernel=7, dilations=[2,4,8,16,32], dropout=0, reg=reg)\n",
    "# X = dilated_residual_convolution(X, kernel=7, dilations=[2,4,8,16,32], dropout=0, reg=reg)\n",
    "# X = TimeDistributed(Conv1D(128,32,  activation='relu'))(X)\n",
    "# out = TimeDistributed(Conv1D(4,1,  activation='softmax'))(X)\n",
    "# X = TimeDistributed(Dense(64, activation='relu'))(X)\n",
    "X = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=None, recurrent_regularizer=None))(X)\n",
    "out = TimeDistributed(Dense(4,  activation='relu'))(X)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "model.compile( optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "               loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "               metrics=['accuracy'],\n",
    "               sample_weight_mode=\"temporal\")\n",
    "\n",
    "model.summary(line_length = 100)\n",
    "model.save_weights('untrained_model.h5')\n",
    "\n",
    "# dot_img_file = '/home/kkotzen/tmp/figures/model_definition.png'\n",
    "# tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weightings are assigned as followed:  {0: 0.6149643937176861, 1: 0.5883773081489262, 2: 4.1078751650795855, 3: 2.3209122638221418}\n",
      "Epoch 1/40\n",
      "99/99 [==============================] - 31s 309ms/step - loss: 14.0439 - accuracy: 0.4038 - val_loss: 9.0740 - val_accuracy: 0.3931\n",
      "Epoch 2/40\n",
      "99/99 [==============================] - 30s 299ms/step - loss: 6.7653 - accuracy: 0.4065 - val_loss: 5.2157 - val_accuracy: 0.3931\n",
      "Epoch 3/40\n",
      "99/99 [==============================] - 30s 301ms/step - loss: 4.4319 - accuracy: 0.4065 - val_loss: 3.7988 - val_accuracy: 0.3931\n",
      "Epoch 4/40\n",
      "99/99 [==============================] - 28s 284ms/step - loss: 3.3885 - accuracy: 0.4065 - val_loss: 3.0343 - val_accuracy: 0.3931\n",
      "Epoch 5/40\n",
      "99/99 [==============================] - 29s 291ms/step - loss: 2.7845 - accuracy: 0.4065 - val_loss: 2.5622 - val_accuracy: 0.3931\n",
      "Epoch 6/40\n",
      "99/99 [==============================] - 31s 309ms/step - loss: 2.4007 - accuracy: 0.4065 - val_loss: 2.2542 - val_accuracy: 0.3931\n",
      "Epoch 7/40\n",
      "99/99 [==============================] - 29s 296ms/step - loss: 2.1434 - accuracy: 0.4065 - val_loss: 2.0416 - val_accuracy: 0.3931\n",
      "Epoch 8/40\n",
      "99/99 [==============================] - 29s 288ms/step - loss: 1.9617 - accuracy: 0.4065 - val_loss: 1.8863 - val_accuracy: 0.3931\n",
      "Epoch 9/40\n",
      "99/99 [==============================] - 27s 277ms/step - loss: 1.8265 - accuracy: 0.4065 - val_loss: 1.7713 - val_accuracy: 0.3931\n",
      "Epoch 10/40\n",
      "99/99 [==============================] - 28s 279ms/step - loss: 1.7273 - accuracy: 0.4065 - val_loss: 1.6872 - val_accuracy: 0.3931\n",
      "Epoch 11/40\n",
      "99/99 [==============================] - 27s 276ms/step - loss: 1.6561 - accuracy: 0.4065 - val_loss: 1.6273 - val_accuracy: 0.3931\n",
      "Epoch 12/40\n",
      "99/99 [==============================] - 28s 286ms/step - loss: 1.6048 - accuracy: 0.4065 - val_loss: 1.5838 - val_accuracy: 0.3931\n",
      "Epoch 13/40\n",
      "99/99 [==============================] - 28s 280ms/step - loss: 1.5662 - accuracy: 0.4065 - val_loss: 1.5500 - val_accuracy: 0.3931\n",
      "Epoch 14/40\n",
      "99/99 [==============================] - 29s 289ms/step - loss: 1.5376 - accuracy: 0.4065 - val_loss: 1.5256 - val_accuracy: 0.3931\n",
      "Epoch 15/40\n",
      "99/99 [==============================] - 28s 281ms/step - loss: 1.5153 - accuracy: 0.4065 - val_loss: 1.5052 - val_accuracy: 0.3931\n",
      "Epoch 16/40\n",
      "99/99 [==============================] - 29s 298ms/step - loss: 1.4964 - accuracy: 0.4065 - val_loss: 1.4881 - val_accuracy: 0.3931\n",
      "Epoch 17/40\n",
      "99/99 [==============================] - 31s 310ms/step - loss: 1.4808 - accuracy: 0.4065 - val_loss: 1.4741 - val_accuracy: 0.3931\n",
      "Epoch 18/40\n",
      "99/99 [==============================] - 31s 314ms/step - loss: 1.4685 - accuracy: 0.4065 - val_loss: 1.4634 - val_accuracy: 0.3931\n",
      "Epoch 19/40\n",
      "99/99 [==============================] - 30s 301ms/step - loss: 1.4592 - accuracy: 0.4065 - val_loss: 1.4549 - val_accuracy: 0.3931\n",
      "Epoch 20/40\n",
      "99/99 [==============================] - 31s 310ms/step - loss: 1.4510 - accuracy: 0.4065 - val_loss: 1.4471 - val_accuracy: 0.3931\n",
      "Epoch 21/40\n",
      "99/99 [==============================] - 29s 296ms/step - loss: 1.4440 - accuracy: 0.4065 - val_loss: 1.4409 - val_accuracy: 0.3931\n",
      "Epoch 22/40\n",
      "99/99 [==============================] - 33s 332ms/step - loss: 1.4381 - accuracy: 0.4065 - val_loss: 1.4355 - val_accuracy: 0.3931\n",
      "Epoch 23/40\n",
      "99/99 [==============================] - 33s 328ms/step - loss: 1.4335 - accuracy: 0.4065 - val_loss: 1.4315 - val_accuracy: 0.3931\n",
      "Epoch 24/40\n",
      "99/99 [==============================] - 33s 337ms/step - loss: 1.4302 - accuracy: 0.4065 - val_loss: 1.4289 - val_accuracy: 0.3931\n",
      "Epoch 25/40\n",
      "99/99 [==============================] - 31s 310ms/step - loss: 1.4274 - accuracy: 0.4065 - val_loss: 1.4262 - val_accuracy: 0.3931\n",
      "Epoch 26/40\n",
      "99/99 [==============================] - 28s 278ms/step - loss: 1.4250 - accuracy: 0.4065 - val_loss: 1.4238 - val_accuracy: 0.3931\n",
      "Epoch 27/40\n",
      "99/99 [==============================] - ETA: 0s - loss: 1.4229 - accuracy: 0.4065"
     ]
    }
   ],
   "source": [
    "model.load_weights('untrained_model.h5')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "mc = ModelCheckpoint('trained_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "callbacks = [es, mc]\n",
    "\n",
    "class_weights, sample_weights = calc_class_sample_weights(train_Y)\n",
    "print('Weightings are assigned as followed: ', class_weights)\n",
    "history = model.fit(train_X_, train_Y_, epochs = 40, batch_size=16, validation_data=(validate_X_, validate_Y_), validation_batch_size=16, verbose=1, callbacks=callbacks, sample_weight=sample_weights, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "plt.close(\"all\")\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hypnogram(label, prediction, patient, ticks):\n",
    "    f, (ax1) = plt.subplots(1, 1, figsize=(15, 10))\n",
    "    ax1.plot(prediction, color='black', label='Predicted sleep stage')\n",
    "    ax1.plot(label, color='red', alpha=0.25, label='Labeled sleep stage')\n",
    "    ax1.set_xlabel('Time (30s Epochs)')\n",
    "    ax1.set_ylabel('Sleep Stage')\n",
    "    ax1.set_yticks(list(ticks.keys()))\n",
    "    ax1.set_yticklabels(list(ticks.values()), rotation='vertical')\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    f.suptitle(f\"Hypnogram for patient {patient}\", fontsize=14)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/home/kkotzen/research/PPG_sleepstaging/trained_model.h5')\n",
    "print(\"Model loaded. Starting prediction\")\n",
    "\n",
    "probs = model.predict(test_X_)\n",
    "print(probs.shape)\n",
    "preds = np.argmax(probs, axis=2)\n",
    "print(preds.shape)\n",
    "\n",
    "patient = 4\n",
    "label = test_Y_[patient]\n",
    "prediction = preds[patient]\n",
    "hypnograms = plot_hypnogram(label, prediction, patient, ticks={0: 'Wake', 1: 'Light', 2:'Deep', 3:'REM'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, cohen_kappa_score\n",
    "\n",
    "from src.models.model_utils import *\n",
    "from utils.figures import make_confusion_matrix\n",
    "\n",
    "labels = {0: 'Wake', 1: 'Light', 2:'Deep', 3:'REM'}\n",
    "\n",
    "test_predictions_probs = model.predict(test_X, batch_size=32, verbose=1)\n",
    "test_predictions = prediction_from_probability(test_predictions_probs)\n",
    "test_lables = flatten_labels(test_Y)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf = confusion_matrix(test_lables, test_predictions, labels=None, sample_weight=None, normalize=None)\n",
    "conf_norm = confusion_matrix(test_lables, test_predictions, labels=None, sample_weight=None, normalize='true')\n",
    "conf_matrix_dict = {'matrix': conf, 'labels': list(labels)}\n",
    "conf_matrix_figure = make_confusion_matrix(y_reference=test_lables, y_predicted=test_predictions, categories=list(labels))\n",
    "\n",
    "# Evaluation Metrics\n",
    "auc = \"\"  # tf.keras.metrics.AUC(multi_label=True)(self.dense_to_sparse(test_lables), test_predictions_probs)\n",
    "cr = pd.DataFrame(classification_report(test_lables, test_predictions, output_dict=True)).T\n",
    "acc = accuracy_score(test_lables, test_predictions)\n",
    "kappa = cohen_kappa_score(test_lables, test_predictions)\n",
    "\n",
    "conf = pd.DataFrame(conf, columns=labels, index=labels)\n",
    "conf_norm = pd.DataFrame(conf_norm, columns=labels, index=labels)\n",
    "print(conf)\n",
    "print(conf_norm)\n",
    "print(print(f'\\Classification Report', 'green'))\n",
    "print(cr)\n",
    "print('\\nAccuracy:\\t', acc, '\\nAUC', auc, '\\nKappa\\t\\t', kappa, '\\nWeighted F1\\t',\n",
    "      cr['f1-score']['macro avg'])\n",
    "\n",
    "metrics = {'Weighted F1': cr['f1-score']['weighted avg'], 'Accuracy:': acc, 'AUC': auc,\n",
    "           'Kappa': kappa, 'Macro F1': cr['f1-score']['macro avg']}\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "constant_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _time_series_subsequences(ts, window, hop=1):\n",
    "    assert len(ts.shape) == 1\n",
    "    shape = (int(int(ts.size - window) / hop + 1), window)\n",
    "    strides = ts.strides[0] * hop, ts.strides[0]\n",
    "    return np.lib.stride_tricks.as_strided(ts, shape=shape, strides=strides)\n",
    "\n",
    "\n",
    "def _batch_subsequenced_padded(X, win_len, hop):\n",
    "    padding = int(win_len/2 - hop/2)\n",
    "    X__ = np.zeros((X.shape[0], X.shape[1]+2*padding, X.shape[2]))\n",
    "    X__[:,padding:-padding,:] = X\n",
    "    X_ = np.zeros((X.shape[0], 12, win_len))\n",
    "    for i in range(X.shape[0]):\n",
    "        X_[i] = _time_series_subsequences(X__[i].flatten(), win_len, hop)\n",
    "    return X_\n",
    "\n",
    "\n",
    "d = np.ones((10,120,1))\n",
    "dd = _batch_subsequenced_padded(d, 14, 10)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}