{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"  # Set the GPU you wish to use here\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], enable=True)\n",
    "\n",
    "from tensorflow.python.keras import Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Conv1D, GlobalAveragePooling1D, AveragePooling1D, MaxPool1D, Flatten, Dense, \\\n",
    "    Reshape, Dropout, TimeDistributed, Add, LSTM, GRU, Bidirectional\n",
    "from tensorflow.python.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "os.chdir('/home/kkotzen/research/PPG_sleepstaging/')\n",
    "from src.models.model_utils import plot_hypnogram\n",
    "from src.parsing.MESAParser import MESAParser\n",
    "\n",
    "\n",
    "def comp_google_ihr(patient, dl):\n",
    "    beats = dl.load_annotation(patient, signal='EKG', annotator='epltd0', annotation='Peaks')\n",
    "    beats = beats/dl.ecg_fs\n",
    "    ibi = np.diff(beats)\n",
    "    beats = beats[:-1]+(beats[1:] - beats[:-1])/2\n",
    "    upper = np.percentile(ibi, 99)\n",
    "    lower = np.percentile(ibi, 1)\n",
    "    ibi_filt_idx = np.where((ibi < upper) & (ibi > lower))\n",
    "    ibi = ibi[ibi_filt_idx]\n",
    "    beats = beats[ibi_filt_idx]\n",
    "    ihr = 1/ibi\n",
    "    ihr = (ihr - np.mean(ihr))/np.std(ihr)\n",
    "\n",
    "    x_2hz = np.arange(0, beats[-1], 1/2)\n",
    "    ihr_2hz = np.interp(x_2hz, beats, ihr)\n",
    "    return ihr_2hz\n",
    "\n",
    "def _time_series_subsequences(ts, window, hop=1):\n",
    "    assert len(ts.shape) == 1\n",
    "    shape = (int(int(ts.size - window) / hop + 1), window)\n",
    "    strides = ts.strides[0] * hop, ts.strides[0]\n",
    "    return np.lib.stride_tricks.as_strided(ts, shape=shape, strides=strides)\n",
    "\n",
    "def load_XY(dl, patients):\n",
    "\n",
    "    ihr_fs = 2\n",
    "    ihr_resampled_fs = 128/60\n",
    "    samples_per_epoch = 64\n",
    "    total_epochs = 1200\n",
    "    total_samples = int(samples_per_epoch*1200)\n",
    "    batch_size = len(patients)\n",
    "    sleep_string_encoding = {0:'zero', 1:'one', 2:'two', 3:'three', 4:'four', 5: \"five\"}\n",
    "    sleep_encoding = {'zero': 0, 'one': 1, 'two': 1, 'three': 2, 'four': 9, 'five': 3}\n",
    "\n",
    "    X = np.zeros((batch_size, total_samples))\n",
    "    Y = np.zeros((batch_size, total_epochs))\n",
    "\n",
    "    for i, patient in tqdm(enumerate(patients)):\n",
    "        patient = str(patient).zfill(4)\n",
    "        \n",
    "#         ihr = dl.load_ihr(patient, signal='EKG', filtered=True)\n",
    "#         ihr = (ihr - np.mean(ihr))/np.std(ihr)\n",
    "        \n",
    "        ihr = comp_google_ihr(patient, dl)\n",
    "        \n",
    "        x = np.arange(0, ihr.shape[0]/2, 1/2)\n",
    "        x_new = np.arange(0, ihr.shape[0]/(128/60), 60/128 )\n",
    "        f = interpolate.interp1d(x, ihr)\n",
    "        ihr = f(x_new)        \n",
    "\n",
    "        sleep = dl.load_sleep(patient)\n",
    "        sleep[sleep > 5] = 0\n",
    "        sleep = [sleep_string_encoding[s] for s in sleep]\n",
    "        sleep = np.array([sleep_encoding[s] for s in sleep])\n",
    "        sleep[sleep > 9] = 0\n",
    "\n",
    "        L = ihr.shape[0]\n",
    "        if L > total_samples:\n",
    "            L = total_samples\n",
    "        X[i, 0:L] = ihr[0:L]\n",
    "        \n",
    "        L = sleep.shape[0]\n",
    "        if L > total_epochs:\n",
    "            L = total_epochs\n",
    "        Y[i, 0:L] = sleep[0:L]\n",
    "\n",
    "    return np.expand_dims(X,axis=2), Y\n",
    "\n",
    "def calc_class_sample_weights(ty, weight_adjustment=[]):\n",
    "    if len(ty.shape) == 1:\n",
    "        y = ty.reshape(ty.shape[0])\n",
    "    else:\n",
    "        y = ty.reshape(ty.shape[0] * ty.shape[1])\n",
    "    classes = np.unique(y)\n",
    "\n",
    "    if len(weight_adjustment) > 0 and len(weight_adjustment) != len(classes):\n",
    "        raise ValueError(\"The weight adjustment variable needs to have as many values as there are classes\")\n",
    "    elif len(weight_adjustment) == 0:\n",
    "        weight_adjustment = np.ones(len(classes))\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=classes, y=y) * weight_adjustment\n",
    "    class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "    sample_weights = np.vectorize(class_weights.get)(ty)\n",
    "    return class_weights, sample_weights\n",
    "\n",
    "def duplicate(x):\n",
    "    return np.array([[x_]*2 for x_ in x]).flatten()\n",
    "\n",
    "def hold_line(t, x):\n",
    "    t = [i for i in t]\n",
    "    x = [i for i in x]\n",
    "    \n",
    "    if len(t) - len(x) == 0:\n",
    "            t.append(t[-1]+t[-1]-t[-2])\n",
    "    if len(t)-len(x) != 1:\n",
    "            raise ValueError()\n",
    "            \n",
    "    t_ = duplicate(t)[1:-1]\n",
    "    x_ = duplicate(x)\n",
    "    return t_, x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1133, 76800, 1) (1133, 1200)\n",
      "(141, 76800, 1) (141, 1200)\n",
      "(141, 76800, 1) (141, 1200)\n"
     ]
    }
   ],
   "source": [
    "dl = MESAParser()\n",
    "train_patients, test_patients= dl.get_train_test_patients_from_file()\n",
    "train_patients, validate_patients = train_test_split(train_patients, test_size = len(test_patients), random_state=6668)\n",
    "    # train_X, train_Y = load_XY(dl, train_patients)\n",
    "    # validate_X, validate_Y = load_XY(dl, validate_patients)\n",
    "    # test_X, test_Y = load_XY(dl, test_patients)\n",
    "\n",
    "    # np.savez(\"train.npz\", train_X=train_X, train_Y=train_Y)\n",
    "    # np.savez(\"validate.npz\", validate_X=validate_X, validate_Y=validate_Y)\n",
    "    # np.savez(\"test.npz\", test_X=test_X, test_Y=test_Y)\n",
    "\n",
    "train = np.load('train.npz')\n",
    "train_X, train_Y = train['train_X'], train['train_Y']\n",
    "validate = np.load('validate.npz')\n",
    "validate_X, validate_Y = validate['validate_X'], validate['validate_Y']\n",
    "test = np.load('test.npz')\n",
    "test_X, test_Y = test['test_X'], test['test_Y']\n",
    "\n",
    "train_Y[train_Y==9] = 0\n",
    "validate_Y[validate_Y==9] = 0\n",
    "test_Y[test_Y==9] = 0\n",
    "\n",
    "print(train_X.shape, train_Y.shape)\n",
    "print(validate_X.shape, validate_Y.shape)\n",
    "print(test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient:  0288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676ec0d4fb8c41b197290746a18edf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1207480be0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "I = 300\n",
    "print(\"Patient: \", train_patients[I])\n",
    "X, Y = train_X[I,:], train_Y[I]\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, (ax1, ax2) = plt.subplots(2,1,figsize=(12, 5), sharex=True)\n",
    "x = np.arange(0, (len(X)/(128/60))/30, (60/128)/30)\n",
    "y = np.arange(0, len(Y), 1)\n",
    "ax1.plot(x,X)\n",
    "\n",
    "\n",
    "y_, Y_ = hold_line(y, Y)\n",
    "ax2.plot(y_,Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fceaf4e40e43598f202a69d12e8c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(train_Y.flatten()).hist(density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                                 Output Shape                            Param #        \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)                         [(None, 76800, 1)]                      0              \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)                            (None, 76800, 8)                        16             \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)                            (None, 76800, 16)                       400            \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)               (None, 38400, 16)                       0              \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)                            (None, 38400, 32)                       1568           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)               (None, 19200, 32)                       0              \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)                            (None, 19200, 64)                       6208           \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)               (None, 9600, 64)                        0              \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)                            (None, 9600, 128)                       24704          \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)               (None, 4800, 128)                       0              \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)                          (None, 1200, 4, 128)                    0              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistributed)         (None, 1200, 512)                       0              \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistributed)         (None, 1200, 128)                       65664          \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistributed)         (None, 1200, 16)                        2064           \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistributed)        (None, 1200, 4)                         68             \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)              (None, 1200, 256)                       136192         \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional)              (None, 1200, 256)                       394240         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistributed)        (None, 1200, 128)                       32896          \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistributed)        (None, 1200, 64)                        8256           \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistributed)        (None, 1200, 4)                         260            \n",
      "====================================================================================================\n",
      "Total params: 672,536\n",
      "Trainable params: 672,536\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def dilated_residual_convolution(X_in, kernel, dilations, reg):\n",
    "    for dilation in dilations:\n",
    "        X = TimeDistributed(Conv1D(128, kernel_size=kernel,  activation='relu', dilation_rate=dilation, padding='same',  kernel_regularizer=reg))(X_in)\n",
    "#     X = TimeDistributed(Dropout(0.2))(X)\n",
    "    X = Add()([X, X_in])\n",
    "    return X\n",
    "\n",
    "reg = None\n",
    "\n",
    "inputs = Input(shape=(validate_X.shape[1], validate_X.shape[2]))\n",
    "\n",
    "# Input Convolution\n",
    "X = Conv1D(8, 1, activation='relu', padding='same', kernel_regularizer=reg)(inputs)\n",
    "# Conv Block 1 of 3\n",
    "X = Conv1D(16, 3, activation='relu', padding='same',  kernel_regularizer=reg)(X)\n",
    "X = MaxPool1D(2, strides=2)(X)\n",
    "\n",
    "# Conv Block 2 of 3\n",
    "X = Conv1D(32, 3, activation='relu', padding='same',  kernel_regularizer=reg)(X)\n",
    "X = MaxPool1D(2, strides=2)(X)\n",
    "\n",
    "# Conv Block 3 of 3\n",
    "X = Conv1D(64, 3, activation='relu', padding='same',  kernel_regularizer=reg)(X)\n",
    "X = MaxPool1D(2, strides=2)(X)\n",
    "\n",
    "# Conv Block 4 of 3\n",
    "X = Conv1D(128, 3, activation='relu', padding='same',  kernel_regularizer=reg)(X)\n",
    "X = MaxPool1D(2, strides=2)(X)\n",
    "\n",
    "X = Reshape(target_shape=(1200, 4, 128))(X)\n",
    "\n",
    "# Flatten + Dense\n",
    "# X = TimeDistributed(AveragePooling1D())(X)\n",
    "X = TimeDistributed(Flatten())(X)\n",
    "X = TimeDistributed(Dense(units=128, activation='relu'))(X)\n",
    "X = TimeDistributed(Dense(units=16, activation='relu'))(X)\n",
    "X = TimeDistributed(Dense(units=4, activation='relu'))(X)\n",
    "X = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=None, recurrent_regularizer=None))(X)\n",
    "X = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=None, recurrent_regularizer=None))(X)\n",
    "X = TimeDistributed(Dense(128, activation='relu', kernel_regularizer=None))(X)\n",
    "X = TimeDistributed(Dense(64, activation='relu', kernel_regularizer=None))(X)\n",
    "out = TimeDistributed(Dense(4, activation='softmax'))(X)\n",
    "        \n",
    "# Time Dilated\n",
    "# X = Reshape(target_shape=(1, X.shape[1], X.shape[2]))(X)\n",
    "# Dilated Residual Connections\n",
    "# X = dilated_residual_convolution(X, kernel=7, dilations=[2,4,8,16,32], reg=reg)\n",
    "# X = dilated_residual_convolution(X, kernel=7, dilations=[2,4,8,16,32], reg=reg)\n",
    "# X = TimeDistributed(Dense(64, activation='relu'))(X)\n",
    "# out = TimeDistributed(Conv1D(4,1,  activation='softmax'))(X)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=out)\n",
    "\n",
    "model.compile( optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "               loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "               metrics=['accuracy'],\n",
    "               sample_weight_mode=\"temporal\")\n",
    "\n",
    "model.summary(line_length = 100)\n",
    "model.save_weights('untrained_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weightings are assigned as followed:  {0: 0.6480988908528249, 1: 0.5737938764933581, 2: 3.8472857336895006, 3: 2.201111240626336}\n",
      "Epoch 1/40\n",
      "71/71 [==============================] - 34s 473ms/step - loss: 1.3079 - accuracy: 0.4386 - val_loss: 1.2812 - val_accuracy: 0.3089\n",
      "Epoch 2/40\n",
      "71/71 [==============================] - 19s 262ms/step - loss: 1.2534 - accuracy: 0.3908 - val_loss: 1.1715 - val_accuracy: 0.4084\n",
      "Epoch 3/40\n",
      "71/71 [==============================] - 18s 256ms/step - loss: 1.2275 - accuracy: 0.3946 - val_loss: 1.1810 - val_accuracy: 0.3970\n",
      "Epoch 4/40\n",
      "71/71 [==============================] - 18s 259ms/step - loss: 1.1893 - accuracy: 0.4160 - val_loss: 1.1762 - val_accuracy: 0.3950\n",
      "Epoch 5/40\n",
      "71/71 [==============================] - 18s 260ms/step - loss: 1.1993 - accuracy: 0.4079 - val_loss: 1.2030 - val_accuracy: 0.3830\n",
      "Epoch 6/40\n",
      "71/71 [==============================] - 18s 255ms/step - loss: 1.1973 - accuracy: 0.4176 - val_loss: 1.1918 - val_accuracy: 0.3950\n",
      "Epoch 7/40\n",
      "71/71 [==============================] - 19s 263ms/step - loss: 1.1368 - accuracy: 0.4345 - val_loss: 1.1489 - val_accuracy: 0.4373\n",
      "Epoch 8/40\n",
      "71/71 [==============================] - 18s 255ms/step - loss: 1.2647 - accuracy: 0.3881 - val_loss: 1.2331 - val_accuracy: 0.3644\n",
      "Epoch 9/40\n",
      "71/71 [==============================] - 19s 266ms/step - loss: 1.2125 - accuracy: 0.4189 - val_loss: 1.1242 - val_accuracy: 0.4471\n",
      "Epoch 10/40\n",
      "71/71 [==============================] - 18s 260ms/step - loss: 1.1523 - accuracy: 0.4306 - val_loss: 1.1190 - val_accuracy: 0.4540\n",
      "Epoch 11/40\n",
      "71/71 [==============================] - 18s 257ms/step - loss: 1.1192 - accuracy: 0.4436 - val_loss: 1.1299 - val_accuracy: 0.4279\n",
      "Epoch 12/40\n",
      "71/71 [==============================] - 19s 263ms/step - loss: 1.0711 - accuracy: 0.4684 - val_loss: 1.0120 - val_accuracy: 0.5263\n",
      "Epoch 13/40\n",
      "71/71 [==============================] - 19s 262ms/step - loss: 1.0484 - accuracy: 0.4819 - val_loss: 1.0343 - val_accuracy: 0.5227\n",
      "Epoch 14/40\n",
      "71/71 [==============================] - 19s 266ms/step - loss: 1.0231 - accuracy: 0.4938 - val_loss: 1.0979 - val_accuracy: 0.4678\n",
      "Epoch 15/40\n",
      "71/71 [==============================] - 19s 262ms/step - loss: 0.9941 - accuracy: 0.5092 - val_loss: 0.9655 - val_accuracy: 0.5528\n",
      "Epoch 16/40\n",
      "71/71 [==============================] - 19s 265ms/step - loss: 0.9966 - accuracy: 0.5061 - val_loss: 1.0136 - val_accuracy: 0.5174\n",
      "Epoch 17/40\n",
      "71/71 [==============================] - 18s 259ms/step - loss: 0.9396 - accuracy: 0.5401 - val_loss: 0.8999 - val_accuracy: 0.5853\n",
      "Epoch 18/40\n",
      "71/71 [==============================] - 18s 260ms/step - loss: 0.9509 - accuracy: 0.5335 - val_loss: 0.9483 - val_accuracy: 0.5451\n",
      "Epoch 19/40\n",
      "71/71 [==============================] - 18s 256ms/step - loss: 0.8797 - accuracy: 0.5586 - val_loss: 0.9624 - val_accuracy: 0.5476\n",
      "Epoch 20/40\n",
      "71/71 [==============================] - 18s 256ms/step - loss: 0.8562 - accuracy: 0.5739 - val_loss: 0.9754 - val_accuracy: 0.5389\n",
      "Epoch 21/40\n",
      "71/71 [==============================] - 19s 263ms/step - loss: 1.0327 - accuracy: 0.4788 - val_loss: 1.0417 - val_accuracy: 0.4765\n",
      "Epoch 22/40\n",
      "71/71 [==============================] - 18s 257ms/step - loss: 0.9476 - accuracy: 0.5335 - val_loss: 0.9686 - val_accuracy: 0.5610\n",
      "Epoch 23/40\n",
      "71/71 [==============================] - 18s 258ms/step - loss: 0.8431 - accuracy: 0.5782 - val_loss: 0.8784 - val_accuracy: 0.5947\n",
      "Epoch 24/40\n",
      "71/71 [==============================] - 18s 256ms/step - loss: 0.8162 - accuracy: 0.5884 - val_loss: 0.9501 - val_accuracy: 0.5569\n",
      "Epoch 25/40\n",
      "71/71 [==============================] - 19s 262ms/step - loss: 0.7937 - accuracy: 0.6034 - val_loss: 0.8372 - val_accuracy: 0.6184\n",
      "Epoch 26/40\n",
      "71/71 [==============================] - 18s 250ms/step - loss: 0.7794 - accuracy: 0.6096 - val_loss: 0.8907 - val_accuracy: 0.5886\n",
      "Epoch 27/40\n",
      "71/71 [==============================] - 18s 253ms/step - loss: 0.8375 - accuracy: 0.5847 - val_loss: 1.0166 - val_accuracy: 0.4928\n",
      "Epoch 28/40\n",
      "71/71 [==============================] - 18s 253ms/step - loss: 0.8282 - accuracy: 0.5790 - val_loss: 0.9007 - val_accuracy: 0.5727\n",
      "Epoch 29/40\n",
      "71/71 [==============================] - 18s 256ms/step - loss: 0.7881 - accuracy: 0.6055 - val_loss: 0.8436 - val_accuracy: 0.6173\n",
      "Epoch 30/40\n",
      "71/71 [==============================] - 19s 262ms/step - loss: 0.7588 - accuracy: 0.6203 - val_loss: 0.8303 - val_accuracy: 0.6190\n",
      "Epoch 31/40\n",
      "71/71 [==============================] - 18s 257ms/step - loss: 0.7234 - accuracy: 0.6336 - val_loss: 0.8119 - val_accuracy: 0.6293\n",
      "Epoch 32/40\n",
      "71/71 [==============================] - 18s 252ms/step - loss: 0.7110 - accuracy: 0.6400 - val_loss: 0.8308 - val_accuracy: 0.6225\n",
      "Epoch 33/40\n",
      "71/71 [==============================] - 18s 257ms/step - loss: 0.6948 - accuracy: 0.6489 - val_loss: 0.8732 - val_accuracy: 0.6049\n",
      "Epoch 34/40\n",
      "71/71 [==============================] - 19s 262ms/step - loss: 0.6940 - accuracy: 0.6475 - val_loss: 0.7962 - val_accuracy: 0.6390\n",
      "Epoch 35/40\n",
      "71/71 [==============================] - 18s 259ms/step - loss: 0.6778 - accuracy: 0.6554 - val_loss: 0.8101 - val_accuracy: 0.6302\n",
      "Epoch 36/40\n",
      "71/71 [==============================] - 19s 263ms/step - loss: 0.6633 - accuracy: 0.6621 - val_loss: 0.8727 - val_accuracy: 0.6000\n",
      "Epoch 37/40\n",
      "71/71 [==============================] - 19s 262ms/step - loss: 0.6610 - accuracy: 0.6628 - val_loss: 0.7404 - val_accuracy: 0.6792\n",
      "Epoch 38/40\n",
      "71/71 [==============================] - 18s 253ms/step - loss: 0.6475 - accuracy: 0.6703 - val_loss: 0.7683 - val_accuracy: 0.6569\n",
      "Epoch 39/40\n",
      "71/71 [==============================] - 18s 257ms/step - loss: 0.6341 - accuracy: 0.6772 - val_loss: 0.7867 - val_accuracy: 0.6513\n",
      "Epoch 40/40\n",
      "71/71 [==============================] - 19s 265ms/step - loss: 0.6329 - accuracy: 0.6747 - val_loss: 0.7543 - val_accuracy: 0.6656\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('untrained_model.h5')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "mc = ModelCheckpoint('trained_model.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
    "callbacks = [es, mc]\n",
    "\n",
    "class_weights, sample_weights = calc_class_sample_weights(train_Y)\n",
    "print('Weightings are assigned as followed: ', class_weights)\n",
    "history = model.fit(train_X, train_Y, epochs = 40, batch_size=16, validation_data=(validate_X, validate_Y), validation_batch_size=16, verbose=1, callbacks=callbacks, sample_weight=sample_weights, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "plt.close(\"all\")\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hypnogram(label, prediction, patient, ticks):\n",
    "    f, (ax1) = plt.subplots(1, 1, figsize=(15, 10))\n",
    "    ax1.plot(prediction, color='black', label='Predicted sleep stage')\n",
    "    ax1.plot(label, color='red', alpha=0.25, label='Labeled sleep stage')\n",
    "    ax1.set_xlabel('Time (30s Epochs)')\n",
    "    ax1.set_ylabel('Sleep Stage')\n",
    "    ax1.set_yticks(list(ticks.keys()))\n",
    "    ax1.set_yticklabels(list(ticks.values()), rotation='vertical')\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    f.suptitle(f\"Hypnogram for patient {patient}\", fontsize=14)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Starting prediction\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('/home/kkotzen/research/PPG_sleepstaging/trained_model.h5')\n",
    "print(\"Model loaded. Starting prediction\")\n",
    "\n",
    "probs = model.predict(test_X)\n",
    "print(probs.shape)\n",
    "preds = np.argmax(probs, axis=2)\n",
    "print(preds.shape)\n",
    "\n",
    "patient = 2\n",
    "label = test_Y[patient]\n",
    "prediction = preds[patient]\n",
    "hypnograms = plot_hypnogram(label, prediction, patient, ticks={0: 'Wake', 1: 'Light', 2:'Deep', 3:'REM'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 90ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d00ea16076c4c4aa3e0e2637481c1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1      2      3\n",
      "0  51184   9479   1962   4531\n",
      "1   6615  38111  18593   8599\n",
      "2    417   2241   7779    438\n",
      "3   1660   3032    757  13802\n",
      "          0         1         2         3\n",
      "0  0.762166  0.141149  0.029216  0.067470\n",
      "1  0.091980  0.529923  0.258531  0.119567\n",
      "2  0.038345  0.206069  0.715310  0.040276\n",
      "3  0.086229  0.157498  0.039323  0.716950\n",
      "\\Classification Report green\n",
      "None\n",
      "              precision    recall  f1-score        support\n",
      "0.0            0.854833  0.762166  0.805844   67156.000000\n",
      "1.0            0.720939  0.529923  0.610846   71918.000000\n",
      "2.0            0.267402  0.715310  0.389281   10875.000000\n",
      "3.0            0.504275  0.716950  0.592094   19251.000000\n",
      "accuracy       0.655296  0.655296  0.655296       0.655296\n",
      "macro avg      0.586862  0.681087  0.599516  169200.000000\n",
      "weighted avg   0.720281  0.655296  0.671867  169200.000000\n",
      "\n",
      "Accuracy:\t 0.6552955082742317 \n",
      "AUC  \n",
      "Kappa\t\t 0.505653088152623 \n",
      "Weighted F1\t 0.5995162449310348\n",
      "{'Weighted F1': 0.6718672304652197, 'Accuracy:': 0.6552955082742317, 'AUC': '', 'Kappa': 0.505653088152623, 'Macro F1': 0.5995162449310348}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, cohen_kappa_score\n",
    "\n",
    "from src.models.model_utils import *\n",
    "from utils.figures import make_confusion_matrix\n",
    "\n",
    "labels = {0: 'Wake', 1: 'Light', 2:'Deep', 3:'REM'}\n",
    "\n",
    "test_predictions_probs = model.predict(test_X, batch_size=32, verbose=1)\n",
    "test_predictions = prediction_from_probability(test_predictions_probs)\n",
    "test_lables = flatten_labels(test_Y)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf = confusion_matrix(test_lables, test_predictions, labels=None, sample_weight=None, normalize=None)\n",
    "conf_norm = confusion_matrix(test_lables, test_predictions, labels=None, sample_weight=None, normalize='true')\n",
    "conf_matrix_dict = {'matrix': conf, 'labels': list(labels)}\n",
    "conf_matrix_figure = make_confusion_matrix(y_reference=test_lables, y_predicted=test_predictions, categories=list(labels))\n",
    "\n",
    "# Evaluation Metrics\n",
    "auc = \"\"  # tf.keras.metrics.AUC(multi_label=True)(self.dense_to_sparse(test_lables), test_predictions_probs)\n",
    "cr = pd.DataFrame(classification_report(test_lables, test_predictions, output_dict=True)).T\n",
    "acc = accuracy_score(test_lables, test_predictions)\n",
    "kappa = cohen_kappa_score(test_lables, test_predictions)\n",
    "\n",
    "conf = pd.DataFrame(conf, columns=labels, index=labels)\n",
    "conf_norm = pd.DataFrame(conf_norm, columns=labels, index=labels)\n",
    "print(conf)\n",
    "print(conf_norm)\n",
    "print(print(f'\\Classification Report', 'green'))\n",
    "print(cr)\n",
    "print('\\nAccuracy:\\t', acc, '\\nAUC', auc, '\\nKappa\\t\\t', kappa, '\\nWeighted F1\\t',\n",
    "      cr['f1-score']['macro avg'])\n",
    "\n",
    "metrics = {'Weighted F1': cr['f1-score']['weighted avg'], 'Accuracy:': acc, 'AUC': auc,\n",
    "           'Kappa': kappa, 'Macro F1': cr['f1-score']['macro avg']}\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
